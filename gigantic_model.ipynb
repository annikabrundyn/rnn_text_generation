{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 'gigantic' model trained on Alice in Wonderland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "Alice in Wonderland (full book)\n",
    "\n",
    "Char-Sequence Length = 100\n",
    "\n",
    "### Model: \n",
    "3-layer LSTM, 700 hidden states, dropout ratio = 0.2\n",
    "weights randomly initialised\n",
    "\n",
    "### Training:\n",
    "28 epochs in total, batch size of 128\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (open(\"wonderland.txt\").read())\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Alice in Wonderland data with 143552 characters.\n",
      "FIRST 1000 CHARACTERS: \n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought alice 'without pictures or\n",
      "conversations?'\n",
      "\n",
      "so she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure\n",
      "of making a daisy-chain would be worth the trouble of getting up and\n",
      "picking the daisies, when suddenly a white rabbit with pink eyes ran\n",
      "close by her.\n",
      "\n",
      "there was nothing so very remarkable in that; nor did alice think it so\n",
      "very much out of the way to hear the rabbit say to itself, 'oh dear!\n",
      "oh dear! i shall be late!' (when she thought it over afterwards, it\n",
      "occurred to her that she ought to have wondered at this, but at the time\n",
      "it all seemed quite natural); but when the rabbit actually took a watch\n",
      "out of its waistcoat-pocket, and looked at it, and \n"
     ]
    }
   ],
   "source": [
    "print(\"Downloaded Alice in Wonderland data with {} characters.\".format(len(text)))\n",
    "print(\"FIRST 1000 CHARACTERS: \")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating character/word mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mapping of unique chars to integers, and a reverse mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  42\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(characters)\n",
    "print('Number of unique characters: ', vocab_size)\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []   # extracted sequences\n",
    "Y = []   # the target: follow up character for each sequence in X\n",
    "length = len(text)\n",
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted sequences: 143452\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, length - seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label = text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])\n",
    "    \n",
    "print('Number of extracted sequences:', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, X is our train array, and Y is our target array.\n",
    "\n",
    "seq_length is the length of the sequence of characters that we want to consider before predicting a particular character.\n",
    "\n",
    "The for loop is used to iterate over the entire length of the text and create such sequences (stored in X) and their true values (stored in Y). Now, it’s difficult to visualize the concept of true values here. Let’s understand this with an example:\n",
    "\n",
    "For a sequence length of 4 and the text “hello india”, we would have our X and Y (not encoded as numbers for ease of understanding) as below:\n",
    "\n",
    "|       X      |  Y  |\n",
    "|:------------:|:---:|\n",
    "| [h, e, l, l] | [o] |\n",
    "| [e, l, l, o] | [ ] |\n",
    "| [l, l, o,  ] | [i] |\n",
    "| [l, o,  , i] | [n] |\n",
    "| ...          | ... |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features) which is not the current format of the arrays. Also, we need to transform the array Y into a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first reshape the array X into our required dimensions. Then, we scale the values of our X_modified so that our neural network can train faster and there is a lesser chance of getting stuck in a local minima. Also, our Y_modified is one-hot encoded to remove any ordinal relationship that may have been introduced in the process of mapping the characters. That is, ‘a’ might be assigned a lower number as compared to ‘z’, but that doesn’t signify any relationship between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143452, 100, 1), (143452, 42))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_modified.shape, Y_modified.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[0].shape = (100, 1), Y[0].shape = (42,)\n",
      "X[0]:  [[0.38095238]\n",
      " [0.64285714]\n",
      " [0.57142857]\n",
      " [0.42857143]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.9047619 ]\n",
      " [0.38095238]\n",
      " [0.80952381]\n",
      " [0.02380952]\n",
      " [0.4047619 ]\n",
      " [0.47619048]\n",
      " [0.52380952]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.69047619]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.71428571]\n",
      " [0.02380952]\n",
      " [0.52380952]\n",
      " [0.47619048]\n",
      " [0.83333333]\n",
      " [0.02380952]\n",
      " [0.88095238]\n",
      " [0.47619048]\n",
      " [0.78571429]\n",
      " [0.95238095]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.57142857]\n",
      " [0.78571429]\n",
      " [0.47619048]\n",
      " [0.45238095]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.5       ]\n",
      " [0.02380952]\n",
      " [0.80952381]\n",
      " [0.57142857]\n",
      " [0.83333333]\n",
      " [0.83333333]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.4047619 ]\n",
      " [0.95238095]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.47619048]\n",
      " [0.78571429]\n",
      " [0.02380952]\n",
      " [0.80952381]\n",
      " [0.57142857]\n",
      " [0.80952381]\n",
      " [0.83333333]\n",
      " [0.47619048]\n",
      " [0.78571429]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.69047619]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.54761905]\n",
      " [0.47619048]\n",
      " [0.        ]\n",
      " [0.4047619 ]\n",
      " [0.38095238]\n",
      " [0.69047619]\n",
      " [0.61904762]\n",
      " [0.16666667]\n",
      " [0.02380952]\n",
      " [0.38095238]\n",
      " [0.69047619]\n",
      " [0.45238095]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.5       ]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.38095238]\n",
      " [0.88095238]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.69047619]\n",
      " [0.71428571]\n",
      " [0.83333333]\n",
      " [0.54761905]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.71428571]]\n",
      "Y[0]:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"X[0].shape = {}, Y[0].shape = {}\".format(X_modified[0].shape, Y_modified[0].shape))\n",
    "print(\"X[0]: \", X_modified[0])\n",
    "print(\"Y[0]: \", Y_modified[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A 'gigantic' model (not truly...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all three LSTM unit size from 400 - 700\n",
    "model = Sequential()\n",
    "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model weights before compiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"model_weights/gigantic-improvement-ctd20-07-0.4656.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model_weights/gigantic-improvement-ctd20-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "143452/143452 [==============================] - 1330s 9ms/step - loss: 0.5439\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.54386, saving model to model_weights/gigantic-improvement-ctd20-01-0.5439.hdf5\n",
      "Epoch 2/10\n",
      "143452/143452 [==============================] - 1330s 9ms/step - loss: 0.5209\n",
      "\n",
      "Epoch 00002: loss improved from 0.54386 to 0.52091, saving model to model_weights/gigantic-improvement-ctd20-02-0.5209.hdf5\n",
      "Epoch 3/10\n",
      "143452/143452 [==============================] - 1333s 9ms/step - loss: 0.5009\n",
      "\n",
      "Epoch 00003: loss improved from 0.52091 to 0.50087, saving model to model_weights/gigantic-improvement-ctd20-03-0.5009.hdf5\n",
      "Epoch 4/10\n",
      "143452/143452 [==============================] - 1331s 9ms/step - loss: 0.4901\n",
      "\n",
      "Epoch 00004: loss improved from 0.50087 to 0.49006, saving model to model_weights/gigantic-improvement-ctd20-04-0.4901.hdf5\n",
      "Epoch 5/10\n",
      "143452/143452 [==============================] - 1331s 9ms/step - loss: 0.4785\n",
      "\n",
      "Epoch 00005: loss improved from 0.49006 to 0.47852, saving model to model_weights/gigantic-improvement-ctd20-05-0.4785.hdf5\n",
      "Epoch 6/10\n",
      "143452/143452 [==============================] - 1331s 9ms/step - loss: 0.4720\n",
      "\n",
      "Epoch 00006: loss improved from 0.47852 to 0.47197, saving model to model_weights/gigantic-improvement-ctd20-06-0.4720.hdf5\n",
      "Epoch 7/10\n",
      "143452/143452 [==============================] - 1331s 9ms/step - loss: 0.4656\n",
      "\n",
      "Epoch 00007: loss improved from 0.47197 to 0.46564, saving model to model_weights/gigantic-improvement-ctd20-07-0.4656.hdf5\n",
      "Epoch 8/10\n",
      " 66944/143452 [============>.................] - ETA: 11:51 - loss: 0.4249"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-00d493c4c15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_modified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_modified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=10, batch_size=128, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(X)-1) # or generate random   #random row from the X array\n",
    "string_mapped = list(X[start])\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133622\n",
      "'nothing,' said alice.\n",
      "\n",
      "'nothing whatever?' persisted the king.\n",
      "\n",
      "'nothing whatever,' said alice.\n",
      "\n",
      "'then it doesn't matter which way you go,' said the cat, and vanished.\n",
      "\n",
      "alice waited patiently until it chose to see it again, but it was a queer-shated\n",
      "little sous.\n",
      "\n",
      "'what was that like?' said alice.\n",
      "\n",
      "'well, i should like to be a little larger, sir, if you wouldn't mind,'\n",
      "said alice, who was beginning to\n",
      "see it trot and dounsesisg.\n",
      "\n",
      "'i don't kike the look of it at all,' said the cat. 'do you play c\n"
     ]
    }
   ],
   "source": [
    "print(start)\n",
    "print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
