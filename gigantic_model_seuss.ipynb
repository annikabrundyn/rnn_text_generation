{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Dr Seuss writing with 'gigantic' model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "Dr. Seuss Books and poems\n",
    "\n",
    "Char-Sequence Length = 100\n",
    "\n",
    "### Model: \n",
    "3-layer LSTM, 700 hidden states, dropout ratio = 0.2\n",
    "Initialised the weights of the model to those obtained from training on Alice in Wonderland for 20 epochs.\n",
    "\n",
    "### Training:\n",
    "15 epochs in total, batch size of 128\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of generated text:\n",
    "The seed is provided in square brackets:\n",
    "[today is your day.\n",
    "you're off to great places!\n",
    "you're off and away!\n",
    "\n",
    "you have brains in your head.\n",
    "you have feet in your shoes.]\n",
    "you can learn about trees...\n",
    "and bees...\n",
    "and knees.\n",
    "and knees on trees!\n",
    "and bees on threes!\n",
    "\n",
    "you can read about anchors.\n",
    "and all about ants.\n",
    "you can go by cow.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = \"\"\n",
    "data = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"seuss_texts/individual/\"\n",
    "files = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open (directory+filename, \"r\") as myfile:\n",
    "            data = myfile.read().lower()                   #replace('\\n', ' ')\n",
    "        files.append(filename)\n",
    "    total = total + data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Dr Seuss data with 84917 characters.\n",
      "FIRST 100 CHARACTERS: \n",
      "the sun did not shine.\n",
      "it was too wet to play.\n",
      "so we sat in the house\n",
      "all that cold, cold, wet day.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloaded Dr Seuss data with {} characters.\".format(len(text)))\n",
    "print(\"FIRST 100 CHARACTERS: \")\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove any unwanted characters in Dr Seuss text that are not present in Alice in Wonderland text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  60\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '8', '9', ':', ';', '?', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', ';', '—', '‘', '’', '“', '”', '…', '\\ufeff', '�']\n"
     ]
    }
   ],
   "source": [
    "orig_chars = sorted(list(set(text)))\n",
    "orig_vocab_size = len(orig_chars)\n",
    "print('Number of unique characters: ', orig_vocab_size)\n",
    "print(orig_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# characters present in Alice in Wonderland text\n",
    "alice_chars = ['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "print(len(alice_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['/', '0', '1', '2', '3', '4', '5', '6', '8', '9', '\\xad', ';', '—', '‘', '’', '“', '”', '…', '\\ufeff', '�']\n"
     ]
    }
   ],
   "source": [
    "unwanted_seuss_chars = []\n",
    "for element in orig_chars:\n",
    "    if element not in alice_chars:\n",
    "        unwanted_seuss_chars.append(element)\n",
    "\n",
    "print(len(unwanted_seuss_chars))\n",
    "print(unwanted_seuss_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first replace some obvious ones - that are already in text but different formatting\n",
    "new_seuss_text = text.replace(';', ';')\n",
    "new_seuss_text = new_seuss_text.replace('—', '-')\n",
    "new_seuss_text = new_seuss_text.replace('‘', \"'\")\n",
    "new_seuss_text = new_seuss_text.replace('’', \"'\")\n",
    "new_seuss_text = new_seuss_text.replace('“', '\"')\n",
    "new_seuss_text = new_seuss_text.replace('”', '\"')\n",
    "new_seuss_text = new_seuss_text.replace('…', '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "['/', '0', '1', '2', '3', '4', '5', '6', '8', '9', '\\xad', '\\ufeff', '�']\n"
     ]
    }
   ],
   "source": [
    "unwanted_seuss_chars2 = []\n",
    "for element in sorted(list(set(new_seuss_text))):\n",
    "    if element not in alice_chars:\n",
    "        unwanted_seuss_chars2.append(element)\n",
    "\n",
    "print(len(unwanted_seuss_chars2))\n",
    "print(unwanted_seuss_chars2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace remaining unwanted characters with \"\" using this function\n",
    "\n",
    "def replaceMultiple(mainString, toBeReplaces, newString):\n",
    "    # Iterate over the strings to be replaced\n",
    "    for elem in toBeReplaces :\n",
    "        # Check if string is in the main string\n",
    "        if elem in mainString :\n",
    "            # Replace the string\n",
    "            mainString = mainString.replace(elem, newString)\n",
    "    \n",
    "    return  mainString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the occurrences of characters not in alice characters by \"\"\n",
    "\n",
    "new_seuss_text2 = replaceMultiple(new_seuss_text, unwanted_seuss_chars2 , \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "new_seuss_chars = sorted(list(set(new_seuss_text2)))\n",
    "print(len(new_seuss_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', ']']\n"
     ]
    }
   ],
   "source": [
    "missing_seuss_chars = []\n",
    "for element in alice_chars:\n",
    "    if element not in sorted(list(set(new_seuss_text2))):\n",
    "        missing_seuss_chars.append(element)\n",
    "print(missing_seuss_chars)      \n",
    "# two square brackets don't occur in dr seuss text - add them to the character list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create character mappings consistent with Alice in Wonderland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mapping of unique chars to integers, and a reverse mapping: use alice mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = alice_chars\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  42\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(characters)\n",
    "print('Number of unique characters: ', vocab_size)\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = new_seuss_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []   # extracted sequences\n",
    "Y = []   # the target - the follow up character\n",
    "length = len(text)\n",
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted sequences: 88822\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, length - seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label = text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])\n",
    "    \n",
    "print('Number of extracted sequences:', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, X is our train array, and Y is our target array.\n",
    "\n",
    "seq_length is the length of the sequence of characters that we want to consider before predicting a particular character.\n",
    "\n",
    "The for loop is used to iterate over the entire length of the text and create such sequences (stored in X) and their true values (stored in Y). Now, it’s difficult to visualize the concept of true values here. Let’s understand this with an example:\n",
    "\n",
    "For a sequence length of 4 and the text “hello india”, we would have our X and Y (not encoded as numbers for ease of understanding) as below:\n",
    "\n",
    "|       X      |  Y  |\n",
    "|:------------:|:---:|\n",
    "| [h, e, l, l] | [o] |\n",
    "| [e, l, l, o] | [ ] |\n",
    "| [l, l, o,  ] | [i] |\n",
    "| [l, o,  , i] | [n] |\n",
    "| ...          | ... |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features) which is not the current format of the arrays. Also, we need to transform the array Y into a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first reshape the array X into our required dimensions. Then, we scale the values of our X_modified so that our neural network can train faster and there is a lesser chance of getting stuck in a local minima. Also, our Y_modified is one-hot encoded to remove any ordinal relationship that may have been introduced in the process of mapping the characters. That is, ‘a’ might be assigned a lower number as compared to ‘z’, but that doesn’t signify any relationship between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88822, 100, 1), (88822, 42))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_modified.shape, Y_modified.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[0].shape = (100, 1), Y[0].shape = (42,)\n",
      "X[0]:  [[0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.73809524]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.73809524]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.57142857]\n",
      " [0.80952381]\n",
      " [0.02380952]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.21428571]\n",
      " [0.        ]\n",
      " [0.42857143]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.73809524]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.73809524]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.02380952]\n",
      " [0.42857143]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.21428571]\n",
      " [0.        ]\n",
      " [0.73809524]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.42857143]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.42857143]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.69047619]\n",
      " [0.02380952]\n",
      " [0.73809524]\n",
      " [0.85714286]\n",
      " [0.73809524]\n",
      " [0.21428571]\n",
      " [0.        ]\n",
      " [0.66666667]\n",
      " [0.71428571]\n",
      " [0.85714286]\n",
      " [0.80952381]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.71428571]\n",
      " [0.85714286]\n",
      " [0.80952381]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.66666667]\n",
      " [0.71428571]\n",
      " [0.85714286]\n",
      " [0.80952381]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.69047619]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.71428571]\n",
      " [0.85714286]\n",
      " [0.80952381]\n",
      " [0.47619048]\n",
      " [0.21428571]\n",
      " [0.        ]\n",
      " [0.54761905]\n",
      " [0.71428571]\n",
      " [0.85714286]\n",
      " [0.80952381]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.66666667]\n",
      " [0.71428571]\n",
      " [0.85714286]\n",
      " [0.80952381]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.71428571]]\n",
      "Y[0]:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"X[0].shape = {}, Y[0].shape = {}\".format(X_modified[0].shape, Y_modified[0].shape))\n",
    "print(\"X[0]: \", X_modified[0])\n",
    "print(\"Y[0]: \", Y_modified[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 'gigantic' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all three LSTM unit size from 400 - 700\n",
    "model = Sequential()\n",
    "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(700))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model weights before compiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"model_weights/seuss-gigantic-improvement-ctd06-10-0.4032.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model_weights/seuss-gigantic-improvement-ctd06-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88822/88822 [==============================] - 827s 9ms/step - loss: 0.9790\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.97901, saving model to model_weights/seuss-gigantic-improvement-ctd06-01-0.9790.hdf5\n",
      "Epoch 2/10\n",
      "88822/88822 [==============================] - 824s 9ms/step - loss: 0.8582\n",
      "\n",
      "Epoch 00002: loss improved from 0.97901 to 0.85824, saving model to model_weights/seuss-gigantic-improvement-ctd06-02-0.8582.hdf5\n",
      "Epoch 3/10\n",
      "88822/88822 [==============================] - 823s 9ms/step - loss: 0.7693\n",
      "\n",
      "Epoch 00003: loss improved from 0.85824 to 0.76934, saving model to model_weights/seuss-gigantic-improvement-ctd06-03-0.7693.hdf5\n",
      "Epoch 4/10\n",
      "88822/88822 [==============================] - 823s 9ms/step - loss: 0.6978\n",
      "\n",
      "Epoch 00004: loss improved from 0.76934 to 0.69781, saving model to model_weights/seuss-gigantic-improvement-ctd06-04-0.6978.hdf5\n",
      "Epoch 5/10\n",
      "88822/88822 [==============================] - 822s 9ms/step - loss: 0.6249\n",
      "\n",
      "Epoch 00005: loss improved from 0.69781 to 0.62485, saving model to model_weights/seuss-gigantic-improvement-ctd06-05-0.6249.hdf5\n",
      "Epoch 6/10\n",
      "88822/88822 [==============================] - 822s 9ms/step - loss: 0.5658\n",
      "\n",
      "Epoch 00006: loss improved from 0.62485 to 0.56581, saving model to model_weights/seuss-gigantic-improvement-ctd06-06-0.5658.hdf5\n",
      "Epoch 7/10\n",
      "88822/88822 [==============================] - 822s 9ms/step - loss: 0.5200\n",
      "\n",
      "Epoch 00007: loss improved from 0.56581 to 0.51999, saving model to model_weights/seuss-gigantic-improvement-ctd06-07-0.5200.hdf5\n",
      "Epoch 8/10\n",
      "88822/88822 [==============================] - 822s 9ms/step - loss: 0.4744\n",
      "\n",
      "Epoch 00008: loss improved from 0.51999 to 0.47435, saving model to model_weights/seuss-gigantic-improvement-ctd06-08-0.4744.hdf5\n",
      "Epoch 9/10\n",
      "88822/88822 [==============================] - 822s 9ms/step - loss: 0.4394\n",
      "\n",
      "Epoch 00009: loss improved from 0.47435 to 0.43938, saving model to model_weights/seuss-gigantic-improvement-ctd06-09-0.4394.hdf5\n",
      "Epoch 10/10\n",
      "88822/88822 [==============================] - 822s 9ms/step - loss: 0.4032\n",
      "\n",
      "Epoch 00010: loss improved from 0.43938 to 0.40317, saving model to model_weights/seuss-gigantic-improvement-ctd06-10-0.4032.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f48742390>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=10, batch_size=128, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  night without stop\n",
      "making gluppity-glupp. also schloppity-schlopp.\n",
      "and what do you do with this lef \"\n"
     ]
    }
   ],
   "source": [
    "#start = 70823 #'the more you read...''\n",
    "#start = 18057 #'today is your day...''\n",
    "start = np.random.randint(0, len(X)-1) # or generate random start\n",
    "\n",
    "string_mapped = list(X[start])\n",
    "\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join(full_string), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82613\n",
      " night without stop\n",
      "making gluppity-glupp. also schloppity-schlopp.\n",
      "and what do you do with this leftover goo...\n",
      "\n",
      "when the star-belly sneetches had frankfurter roasts\n",
      "\n",
      "or picnics or parties or marshmallow toasts,\n",
      "\n",
      "they never invited the plain-belly sneetches.\n",
      "\n",
      "they left them out cold, in the dark of the beaches.\n",
      "\n",
      "they kept paying money. they kad she onast band those things\n",
      "yete wacky things more!\n",
      "\n",
      "then i looked up. and i saw three.\n",
      "\n",
      "i went down the hall\n",
      "and i said \"hey!\"\n",
      "thre the grinch thought \n"
     ]
    }
   ],
   "source": [
    "print(start)\n",
    "print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
