{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The baseline model to generate text from Alice in Wonderland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "Alice in Wonderland (full book)\n",
    "\n",
    "Char-Sequence Length = 100\n",
    "\n",
    "### Model: \n",
    "2-layer LSTM, 400 hidden states, dropout ratio = 0.2\n",
    "weights randomly initialised\n",
    "\n",
    "### Training:\n",
    "28 epochs in total, batch size of 128\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RNN\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (open(\"wonderland.txt\").read())\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Alice in Wonderland data with 143552 characters.\n",
      "FIRST 1000 CHARACTERS: \n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, 'and what is the use of a book,' thought alice 'without pictures or\n",
      "conversations?'\n",
      "\n",
      "so she was considering in her own mind (as well as she could, for the\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure\n",
      "of making a daisy-chain would be worth the trouble of getting up and\n",
      "picking the daisies, when suddenly a white rabbit with pink eyes ran\n",
      "close by her.\n",
      "\n",
      "there was nothing so very remarkable in that; nor did alice think it so\n",
      "very much out of the way to hear the rabbit say to itself, 'oh dear!\n",
      "oh dear! i shall be late!' (when she thought it over afterwards, it\n",
      "occurred to her that she ought to have wondered at this, but at the time\n",
      "it all seemed quite natural); but when the rabbit actually took a watch\n",
      "out of its waistcoat-pocket, and looked at it, and \n"
     ]
    }
   ],
   "source": [
    "print(\"Downloaded Alice in Wonderland data with {} characters.\".format(len(text)))\n",
    "print(\"FIRST 1000 CHARACTERS: \")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create character mappings and data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mapping of unique chars to integers, and a reverse mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  42\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(characters)\n",
    "print('Number of unique characters: ', vocab_size)\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get the data in the right format for the required model structure in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []   # extracted sequences\n",
    "Y = []   # the target - the follow up character\n",
    "length = len(text)\n",
    "seq_length = 100   #number of characters to consider before predicting the following character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted sequences: 286904\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, length - seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label = text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])\n",
    "    \n",
    "print('Number of extracted sequences:', len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, X is our train array, and Y is our target array.\n",
    "\n",
    "seq_length is the length of the sequence of characters that we want to consider before predicting a particular character.\n",
    "\n",
    "The for loop is used to iterate over the entire length of the text and create such sequences (stored in X) and their true values (stored in Y). Now, it’s difficult to visualize the concept of true values here. Let’s understand this with an example:\n",
    "\n",
    "For a sequence length of 4 and the text “hello india”, we would have our X and Y (not encoded as numbers for ease of understanding) as below:\n",
    "\n",
    "|       X      |  Y  |\n",
    "|:------------:|:---:|\n",
    "| [h, e, l, l] | [o] |\n",
    "| [e, l, l, o] | [ ] |\n",
    "| [l, l, o,  ] | [i] |\n",
    "| [l, o,  , i] | [n] |\n",
    "| ...          | ... |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features) which is not the current format of the arrays. Also, we need to transform the array Y into a one-hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first reshape the array X into our required dimensions. Then, we scale the values of our X_modified so that our neural network can train faster and there is a lesser chance of getting stuck in a local minima. Also, our Y_modified is one-hot encoded to remove any ordinal relationship that may have been introduced in the process of mapping the characters. That is, ‘a’ might be assigned a lower number as compared to ‘z’, but that doesn’t signify any relationship between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((286904, 100, 1), (286904, 42))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_modified.shape, Y_modified.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[0].shape = (100, 1), Y[0].shape = (42,)\n",
      "X[0]:  [[0.38095238]\n",
      " [0.64285714]\n",
      " [0.57142857]\n",
      " [0.42857143]\n",
      " [0.47619048]\n",
      " [0.02380952]\n",
      " [0.9047619 ]\n",
      " [0.38095238]\n",
      " [0.80952381]\n",
      " [0.02380952]\n",
      " [0.4047619 ]\n",
      " [0.47619048]\n",
      " [0.52380952]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.69047619]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.71428571]\n",
      " [0.02380952]\n",
      " [0.52380952]\n",
      " [0.47619048]\n",
      " [0.83333333]\n",
      " [0.02380952]\n",
      " [0.88095238]\n",
      " [0.47619048]\n",
      " [0.78571429]\n",
      " [0.95238095]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.57142857]\n",
      " [0.78571429]\n",
      " [0.47619048]\n",
      " [0.45238095]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.5       ]\n",
      " [0.02380952]\n",
      " [0.80952381]\n",
      " [0.57142857]\n",
      " [0.83333333]\n",
      " [0.83333333]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.4047619 ]\n",
      " [0.95238095]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.47619048]\n",
      " [0.78571429]\n",
      " [0.02380952]\n",
      " [0.80952381]\n",
      " [0.57142857]\n",
      " [0.80952381]\n",
      " [0.83333333]\n",
      " [0.47619048]\n",
      " [0.78571429]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.69047619]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.54761905]\n",
      " [0.47619048]\n",
      " [0.        ]\n",
      " [0.4047619 ]\n",
      " [0.38095238]\n",
      " [0.69047619]\n",
      " [0.61904762]\n",
      " [0.16666667]\n",
      " [0.02380952]\n",
      " [0.38095238]\n",
      " [0.69047619]\n",
      " [0.45238095]\n",
      " [0.02380952]\n",
      " [0.71428571]\n",
      " [0.5       ]\n",
      " [0.02380952]\n",
      " [0.54761905]\n",
      " [0.38095238]\n",
      " [0.88095238]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.69047619]\n",
      " [0.71428571]\n",
      " [0.83333333]\n",
      " [0.54761905]\n",
      " [0.57142857]\n",
      " [0.69047619]\n",
      " [0.52380952]\n",
      " [0.02380952]\n",
      " [0.83333333]\n",
      " [0.71428571]]\n",
      "Y[0]:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"X[0].shape = {}, Y[0].shape = {}\".format(X_modified[0].shape, Y_modified[0].shape))\n",
    "print(\"X[0]: \", X_modified[0])\n",
    "print(\"Y[0]: \", Y_modified[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model weights before compiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"model_weights/baseline-improvement-06-0.9927.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model_weights/baseline-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "286904/286904 [==============================] - 949s 3ms/step - loss: 1.2354\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.23540, saving model to model_weights/baseline-improvement-01-1.2354.hdf5\n",
      "Epoch 2/6\n",
      "286904/286904 [==============================] - 949s 3ms/step - loss: 1.1685\n",
      "\n",
      "Epoch 00002: loss improved from 1.23540 to 1.16853, saving model to model_weights/baseline-improvement-02-1.1685.hdf5\n",
      "Epoch 3/6\n",
      "286904/286904 [==============================] - 951s 3ms/step - loss: 1.1143\n",
      "\n",
      "Epoch 00003: loss improved from 1.16853 to 1.11433, saving model to model_weights/baseline-improvement-03-1.1143.hdf5\n",
      "Epoch 4/6\n",
      "286904/286904 [==============================] - 949s 3ms/step - loss: 1.0651\n",
      "\n",
      "Epoch 00004: loss improved from 1.11433 to 1.06508, saving model to model_weights/baseline-improvement-04-1.0651.hdf5\n",
      "Epoch 5/6\n",
      "286904/286904 [==============================] - 950s 3ms/step - loss: 1.0688\n",
      "\n",
      "Epoch 00005: loss did not improve from 1.06508\n",
      "Epoch 6/6\n",
      "286904/286904 [==============================] - 950s 3ms/step - loss: 0.9927\n",
      "\n",
      "Epoch 00006: loss improved from 1.06508 to 0.99274, saving model to model_weights/baseline-improvement-06-0.9927.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2a12337f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=6, batch_size=128, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(X)-1) # or generate random start\n",
    "\n",
    "string_mapped = list(X[start])\n",
    "\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join(full_string), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "    \n",
    "    string_mapped.append(pred_index)  # add the predicted character to the end\n",
    "    string_mapped = string_mapped[1:len(string_mapped)] # shift the string one character forward by removing pos. 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"d such things that make children\\nsweet-tempered. i only wish people knew that: then they wouldn't be so dear iikd and taying tie way of the white. but it was a little partering of fead on the thace of the table, serea and she was low and then, and the three gardeners instantly to the eege of the mock turtle in the distance, and the three gardeners instantly wo her her aht anything more time the had seedi in her life, and was going to det note than alice could hear the rest of the court, was suim\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(start)\n",
    "print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
